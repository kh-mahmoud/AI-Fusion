# ğŸ¤– AI-Fusion

ğŸŒŸ AI Models Documentation ğŸŒŸ

AI-Fusion is a powerful AI module that integrates multiple AI models, including Google's Gemini models, Meta's LLaMA, and DeepSeek AI. It provides various AI functionalities for:

âœ… Text Generation â€“ Chatbots, AI responses <br/>
ğŸ¨ Image Processing â€“ Recognition, Generation <br/>
ğŸ¥ Video Analysis â€“ Summarization, Keyframe Extraction <br/>
ğŸ‘¨â€ğŸ’» Code Understanding â€“ AI-assisted coding in Python <br/>
ğŸ“„ Document Processing â€“ PDF Analysis, Embeddings <br/>

---

# ğŸ› ï¸ Available AI Models  

<details open>
  <summary> ğŸ”¹ Google Gemini Models (Text, Image, and Video Processing)</summary>
  <ul style="margin-left: 20px;">
    <li>âœ… <b>geminiFlash</b> â†’ High-speed AI text generation (Gemini-2.0-Flash)</li>
    <li>ğŸ¨ <b>geminiFlashImage</b> â†’ Fast image recognition (Gemini-2.0-Flash)</li>
    <li>ğŸ“ <b>geminitextstream</b> â†’ AI-powered streaming text generation</li>
    <li>ğŸ’¬ <b>geminichat</b> â†’ AI chatbot capabilities</li>
    <li>ğŸ–¼ï¸ <b>generateImage</b> â†’ AI-based image generation</li>
    <li>ğŸ–Œ <b>imagevision</b> â†’ Image recognition (Gemini-1.5-Pro)</li>
    <li>ğŸ¥ <b>videovision</b> â†’ Video analysis and keyframe detection</li>
    <li>ğŸ“º <b>youtubesummarizer</b> â†’ Summarizes YouTube videos</li>
    <li>ğŸ‘¨â€ğŸ’» <b>codertool</b> â†’ AI-powered coding assistant</li>
    <li>ğŸ” <b>embed</b> â†’ Generates vector embeddings for text</li>
    <li>ğŸ“„ <b>pdfreader</b> â†’ Extracts and analyzes text from PDFs</li>
    <li>ğŸš€ <b>gemini_experimental</b> â†’ Latest experimental AI features (Gemini-2.5-Pro-Exp)</li>
    <li>ğŸ­ <b>gemini_experimental_image</b> â†’ Experimental AI image vision (Gemini-2.5-Pro-Exp-Image)</li>
  </ul>
</details>  

<details open>
  <summary>ğŸ”¹ Meta LLaMA Model (Advanced Language Understanding)</summary>
  <ul>
    <li>ğŸ§  <b>meta_llama</b> â†’ LLaMA model for generative AI and chat-based tasks</li>
  </ul>
</details>  

<details open>
  <summary>ğŸ”¹ DeepSeek Model</summary>
  <ul>
    <li>ğŸ¤– <b style="margin-left: 20px">deep_run</b> â†’ DeepSeek-R1, a powerful AI for deep text generation</li>
  </div>
</details>  
    
---
# âš¡ Quick Start Guide
### Clone the Repository  

```bash
git clone https://github.com/kh-mahmoud/AI-Fusion.git
cd AI-Fusion
```
### ğŸ“¦ Install Dependencies 
```bash
npm install
```

### ğŸ”‘ Configure Environment Variables
Create a .env file in the root directory and add the following: <br/>

-- # Gemini Api  <br/>
`GEMENI_API_KEY = your_key_here`  <br/>

-- # Openrouter Api  <br/>
`API_KEY = your_key_here `<br/>

-- # Github marketplace  <br/>
`TOKEN = your_key_here  `  <br/>


# ğŸ“Œ Usage :

choose your model :

```bash
    import {geminiFlash, geminiFlashImage, geminitextstream, geminichat, generateImage, 
    imagevision, videovision, youtubesummarizer, codertool, embed, pdfreader, 
    gemini_experimental, gemini_experimental_image 
    } from "./Gemini/index.js"
    import { meta_llama } from "./LLama/index.js"
    import { deep_run } from "./DeepSeek_R1/index.js"
```

```bash
  await geminiFlash("Generate a short story about AI.")  // Text generation (accepts prompt)
  await meta_llama("What is the capital of France?")  // LLaMA AI chat (accepts prompt)
  await deep_run("Explain the concept of deep learning.") // DeepSeek AI processing (accepts prompt)
 ```

  // Some models accept both prompt and URL:
  
```bash
  await imagevision("Describe the content of this image.", "https://example.com/image.jpg") // Image recognition (accepts prompt and URL)
  await videovision("Analyze this video.", "https://example.com/video.mp4")  // Video analysis (accepts prompt and URL)
  await youtubesummarizer("Summarize the key points.", "https://youtube.com/example_video") // YouTube video summarization (accepts prompt and URL)
  await pdfreader("Extract text from this PDF.", "https://example.com/sample.pdf") // PDF analysis (accepts prompt and URL)
 ```

# ğŸš€ Launch
```bash
node index.js
```



 
  **Note:** Some models require only the `prompt` parameter, while others may require both `prompt` and `url`. For more details, check the model code.




